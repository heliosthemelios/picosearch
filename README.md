# PicoSearch ğŸ¨

PicoSearch est un moteur de recherche spÃ©cialisÃ© dans l'art et la culture, avec une fonctionnalitÃ© de recherche de texte et d'images. Il utilise des web crawlers personnalisÃ©s pour indexer des pages web et des images liÃ©es au domaine artistique.

## ğŸŒŸ FonctionnalitÃ©s

- **Recherche textuelle** : Recherche de pages web indexÃ©es avec mots-clÃ©s multiples
- **Recherche d'images** : DÃ©couverte et indexation d'images d'art
- **Crawling intelligent** : Utilise des mots-clÃ©s spÃ©cifiques au domaine artistique pour cibler les pages pertinentes
- **Respect du robots.txt** : Le spider respecte les rÃ¨gles d'exclusion des sites web
- **Interface web simple et Ã©lÃ©gante** : Interface utilisateur en PHP avec design Ã©purÃ©

## ğŸ“‹ PrÃ©requis

- **Python 3.x**
- **PHP 7.4+**
- **MySQL/MariaDB**
- **Serveur web** (Apache, Nginx, ou serveur PHP intÃ©grÃ©)

### DÃ©pendances Python

```bash
pip install pymysql requests beautifulsoup4 mysql-connector-python python-dotenv
```

## ğŸš€ Installation

### 1. Cloner le projet

```bash
git clone https://github.com/votre-username/picosearch.git
cd picosearch
```

### 2. Configuration de la base de donnÃ©es

CrÃ©ez une base de donnÃ©es MySQL :

```sql
CREATE DATABASE pico CHARACTER SET utf8mb4 COLLATE utf8mb4_unicode_ci;
```

### 3. Configuration des variables d'environnement

Le projet utilise un fichier `.env` pour sÃ©curiser les identifiants de base de donnÃ©es.

#### DÃ©veloppement local

```bash
# Copier le fichier d'exemple
cp .env.example .env

# Ã‰diter le fichier .env avec vos identifiants
nano .env
```

Contenu du fichier `.env` :
```env
DB_HOST=localhost
DB_NAME=pico
DB_USER=votre_utilisateur
DB_PASSWORD=votre_mot_de_passe
USER_AGENT=pico-spider/1.0 (+https://votresite.com)
```

#### DÃ©ploiement en production

**âš ï¸ IMPORTANT pour la sÃ©curitÃ© :**

Le fichier `.env` doit Ãªtre placÃ© **hors du rÃ©pertoire web** pour Ã©viter tout accÃ¨s public.

```bash
# 1. Copier les fichiers PHP dans le rÃ©pertoire web
sudo cp index.php images.php styles.css env_loader.php /var/www/html/

# 2. Copier les scripts Python oÃ¹ vous voulez (ex: home)
cp spider.py spiderimage.py ~/picosearch/

# 3. CrÃ©er le fichier .env HORS du rÃ©pertoire web
sudo nano /var/www/.env
```

Ajoutez vos identifiants dans `/var/www/.env` :
```env
DB_HOST=localhost
DB_NAME=pico
DB_USER=votre_utilisateur
DB_PASSWORD=votre_mot_de_passe_securise
USER_AGENT=pico-spider/1.0 (+https://votresite.com)
```

```bash
# 4. SÃ©curiser les permissions du fichier .env
sudo chmod 600 /var/www/.env
sudo chown www-data:www-data /var/www/.env

# 5. CrÃ©er le dossier images avec les bonnes permissions
sudo mkdir -p /var/www/html/images
sudo chown www-data:www-data /var/www/html/images
sudo chmod 775 /var/www/html/images

# 6. Copier le fichier .htaccess pour bloquer l'accÃ¨s aux fichiers sensibles
sudo cp .htaccess /var/www/html/

# 7. VÃ‰RIFIER que .env n'est PAS accessible publiquement
curl https://votresite.com/.env
# Doit retourner 403 ou 404
```

### 4. Structure de dÃ©ploiement recommandÃ©e

```
/var/www/
â”œâ”€â”€ .env                       â† Fichier de configuration (SÃ‰CURISÃ‰, hors web)
â””â”€â”€ html/                      â† RÃ©pertoire web public
    â”œâ”€â”€ .htaccess             â† Protection des fichiers sensibles
    â”œâ”€â”€ index.php             â† Interface de recherche
    â”œâ”€â”€ images.php            â† Interface de recherche d'images
    â”œâ”€â”€ env_loader.php        â† Chargeur de variables d'environnement
    â”œâ”€â”€ styles.css
    â””â”€â”€ images/               â† Images tÃ©lÃ©chargÃ©es

/home/utilisateur/picosearch/  â† Scripts Python (peuvent Ãªtre ailleurs)
â”œâ”€â”€ spider.py
â””â”€â”€ spiderimage.py
```

### 5. Lancer le serveur (dÃ©veloppement local)

```bash
php -S localhost:8000
```

AccÃ©dez ensuite Ã  `http://localhost:8000/index.php`

## ğŸ“– Utilisation

### Crawler de texte (spider.py)

Lance le crawler pour indexer des pages web :

```bash
# Depuis le rÃ©pertoire oÃ¹ se trouve spider.py
python3 spider.py --seed "https://www.example-art-site.com"

# Crawl avec nombre maximum de pages
python3 spider.py --seed "https://www.example-art-site.com" --max-pages 100

# Depuis n'importe oÃ¹ (si dans /home/utilisateur/picosearch/)
python3 ~/picosearch/spider.py --seed "https://www.example-art-site.com"
```

**Options disponibles :**
- `--seed` : URL de dÃ©part pour le crawling
- `--max-pages` : Nombre maximum de pages Ã  crawler (dÃ©faut: pas de limite)

**Note :** Le script cherche automatiquement le fichier `.env` dans `/var/www/.env` en production ou dans son propre rÃ©pertoire en local.

### Crawler d'images (spiderimage.py)

Lance le crawler pour tÃ©lÃ©charger et indexer des images :

```bash
python3 spiderimage.py
```

Le script :
- Lit les URLs de dÃ©part depuis la table `links`
- TÃ©lÃ©charge les images pertinentes
- Stocke les images dans le dossier `/var/www/html/images/`
- Enregistre les mÃ©tadonnÃ©es dans la table `images`

**Note :** Assurez-vous que l'utilisateur exÃ©cutant le script a les permissions d'Ã©criture dans `/var/www/html/images/`

### Interface de recherche

1. **Recherche textuelle** : AccÃ©dez Ã  `index.php`
   - Saisissez vos mots-clÃ©s sÃ©parÃ©s par des espaces
   - Les rÃ©sultats combinent la recherche dans le titre, l'URL et le snippet

2. **Recherche d'images** : AccÃ©dez Ã  `images.php`
   - Recherchez parmi les images indexÃ©es
   - Visualisez les images avec leurs informations

## ğŸ—‚ï¸ Structure du projet

### DÃ©veloppement local
```
picosearch/
â”œâ”€â”€ .env                   # Variables d'environnement (NON versionnÃ©)
â”œâ”€â”€ .env.example           # Template de configuration
â”œâ”€â”€ .gitignore            # Fichiers Ã  ignorer par Git
â”œâ”€â”€ .htaccess             # Protection Apache
â”œâ”€â”€ spider.py             # Crawler de pages web
â”œâ”€â”€ spiderimage.py        # Crawler d'images
â”œâ”€â”€ index.php             # Interface de recherche textuelle
â”œâ”€â”€ images.php            # Interface de recherche d'images
â”œâ”€â”€ env_loader.php        # Chargeur de variables d'environnement
â”œâ”€â”€ styles.css            # Feuilles de style
â”œâ”€â”€ debug_env.php         # Script de dÃ©bogage (Ã  supprimer en production)
â”œâ”€â”€ migrate_unique_index.php # Script de migration de base de donnÃ©es
â”œâ”€â”€ README.md             # Documentation
â””â”€â”€ images/               # Dossier des images tÃ©lÃ©chargÃ©es
```

### Production (serveur web)
```
/var/www/
â”œâ”€â”€ .env                       â† Configuration sÃ©curisÃ©e (HORS rÃ©pertoire web)
â””â”€â”€ html/
    â”œâ”€â”€ .htaccess
    â”œâ”€â”€ index.php
    â”œâ”€â”€ images.php
    â”œâ”€â”€ env_loader.php
    â”œâ”€â”€ styles.css
    â””â”€â”€ images/

/home/utilisateur/picosearch/  â† Scripts Python
â”œâ”€â”€ spider.py
â””â”€â”€ spiderimage.py
```

## ğŸ—„ï¸ SchÃ©ma de base de donnÃ©es

### Table `links`
Stocke les pages web indexÃ©es :
- `id` : Identifiant unique
- `url` : URL de la page (unique)
- `title` : Titre de la page
- `snippet` : Extrait du contenu

### Table `images`
Stocke les images indexÃ©es :
- `id` : Identifiant unique
- `url` : URL source de l'image
- `alt_text` : Texte alternatif
- `filename` : Nom du fichier local
- `page_url` : URL de la page contenant l'image

## ğŸ¯ Mots-clÃ©s ciblÃ©s

Le moteur se concentre sur le domaine artistique avec des mots-clÃ©s comme :
- Art, musÃ©e, galerie
- Photographie, peinture, sculpture
- Artiste, exposition, installation
- Art contemporain, art moderne
- Et bien d'autres termes liÃ©s Ã  l'art

## ğŸš« Liste noire

Pour Ã©viter de crawler des sites non pertinents, ces domaines sont exclus :
- RÃ©seaux sociaux (Facebook, Twitter, Instagram, etc.)
- Moteurs de recherche
- Sites de commerce en ligne

## âš™ï¸ Configuration avancÃ©e

### ParamÃ¨tres du crawler (spider.py)

```python
MAX_QUEUE_SIZE = 100   # Taille max de la file d'attente
MAX_PER_SITE = 30      # Pages max par domaine
```

### ParamÃ¨tres du crawler d'images (spiderimage.py)

```python
IMAGES_PER_PAGE = 50   # Nombre max d'images par page
```

## ğŸ”§ Migration de base de donnÃ©es

Pour appliquer des migrations sur la base de donnÃ©es, utilisez :

```bash
php migrate_unique_index.php
```

## ğŸ“ Notes importantes

- **Respect des sites web** : Les crawlers respectent les fichiers `robots.txt` et incluent des dÃ©lais entre les requÃªtes
- **Performance** : Pour de grandes quantitÃ©s de donnÃ©es, envisagez d'indexer avec des services comme Elasticsearch
- **SÃ©curitÃ©** : 
  - âš ï¸ **CRITIQUE** : Ne versionnez JAMAIS le fichier `.env` sur Git
  - Le fichier `.env` doit Ãªtre placÃ© **hors** du rÃ©pertoire web public (`/var/www/` et non `/var/www/html/`)
  - Utilisez des mots de passe forts et uniques pour MySQL
  - Le fichier `.gitignore` est configurÃ© pour protÃ©ger automatiquement `.env` et les fichiers sensibles
  - VÃ©rifiez toujours que `https://votresite.com/.env` retourne 403/404
- **Permissions** :
  - `.env` doit avoir les permissions `600` (lecture/Ã©criture propriÃ©taire uniquement)
  - Le dossier `images/` doit Ãªtre accessible en Ã©criture par PHP et Python

## ğŸ”’ Checklist de sÃ©curitÃ© avant dÃ©ploiement

- [ ] Le fichier `.env` est dans `/var/www/` (PAS dans `/var/www/html/`)
- [ ] Les permissions du `.env` sont `600`
- [ ] Le `.env` n'est PAS accessible via navigateur (test: `curl https://votresite.com/.env`)
- [ ] Le fichier `.env.example` ne contient PAS de vrais identifiants
- [ ] Les fichiers `.py` ne sont PAS dans `/var/www/html/`
- [ ] Le fichier `debug_env.php` a Ã©tÃ© supprimÃ© du serveur
- [ ] Le `.htaccess` est prÃ©sent dans `/var/www/html/`
- [ ] Git ignore bien le fichier `.env` (vÃ©rifier avec `git status`)

## ğŸ¤ Contribution

Les contributions sont les bienvenues ! N'hÃ©sitez pas Ã  ouvrir une issue ou soumettre une pull request.

## ğŸ“„ Licence

Ce projet est sous licence MIT - voir le fichier LICENSE pour plus de dÃ©tails.

## ğŸ‘¤ Auteur

Eric Bertrand

## ğŸ”— Liens utiles

- [Documentation BeautifulSoup](https://www.crummy.com/software/BeautifulSoup/bs4/doc/)
- [Documentation Requests](https://docs.python-requests.org/)
- [Documentation PyMySQL](https://pymysql.readthedocs.io/)

---

â­ Si ce projet vous plaÃ®t, n'hÃ©sitez pas Ã  lui donner une Ã©toile sur GitHub !
